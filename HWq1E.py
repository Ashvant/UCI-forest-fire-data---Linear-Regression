import mnist
import matplotlib.pyplot as plt
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
import math
from scipy.spatial.distance import directed_hausdorff
x_train, t_train, x_test, t_test = mnist.load()
X = x_train
y = t_train
neighbours = []
scores_training = []
scores_test = []
def hausdroffDistanceCalc(a,b):
    return max(directed_hausdorff((a).reshape(28,28), (b).reshape(28,28))[0],directed_hausdorff((b).reshape(28,28), (a).reshape(28,28))[0])
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=1)
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Manahttan error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,1/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.1) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,2/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.2) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,3/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.3) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,4/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.4) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,5/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.5) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,6/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.6) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,7/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.7) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,8/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.8) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,9/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(0.9) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="minkowski",p=math.pow(10,10/10))
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Minkowski p = log(1.0) error")
#print(1-scores2)
#neigh = KNeighborsClassifier(n_neighbors=3,metric="chebyshev")
#neigh.fit(X[:30000],y[:30000])
#scores2 = neigh.score(x_test[:5000],t_test[:5000])
#print("Chebyshev error")
#print(1-scores2)
neigh = KNeighborsClassifier(n_neighbors=3,metric="mahalanobis",metric_params={'VI': np.cov(X[:1000])},algorithm="brute")
neigh.fit(X[:1000],y[:1000])
scores2 = neigh.score(x_test[:50],t_test[:50])
print("Mahalanobis error")
print(1-scores2)
neigh = KNeighborsClassifier(n_neighbors=3,metric=hausdroffDistanceCalc)
neigh.fit(X[:30000],y[:30000])
scores2 = neigh.score(x_test[:5000],t_test[:5000])
print("Hausdroff error")
print(1-scores2)
#scores_test.append(1-scores2)
#plt.plot(neighbours,scores_training,label="training error")
#plt.plot(neighbours,scores_test,label="test error")
#plt.xlabel('i/k')
#plt.ylabel('error')
#
#plt.show()